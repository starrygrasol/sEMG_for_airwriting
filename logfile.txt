==================== 加载预处理数据 ====================
输入形状: (1000, 64, 64, 16), 标签形状: (1000,)

==================== 开始数据集划分 ====================
数据集划分完成 - 训练集: 700, 验证集: 150, 测试集: 150
==================== 数据集划分完成 ====================


=== 正在训练 deeper_model ===
[DEBUG] X_train原始形状: (700, 64, 64, 16)
[DEBUG] y_train形状: (700,)
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 64, 64, 16)]      0
_________________________________________________________________
conv2d (Conv2D)              (None, 64, 64, 64)        9280
_________________________________________________________________
batch_normalization (BatchNo (None, 64, 64, 64)        256
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0
_________________________________________________________________
dropout (Dropout)            (None, 32, 32, 64)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 32, 32, 128)       73856
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 128)       512
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 16, 128)       0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 16, 16, 256)       295168
_________________________________________________________________
batch_normalization_2 (Batch (None, 16, 16, 256)       1024
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0
_________________________________________________________________
flatten (Flatten)            (None, 16384)             0
_________________________________________________________________
dropout_2 (Dropout)          (None, 16384)             0
_________________________________________________________________
dense (Dense)                (None, 512)               8389120
_________________________________________________________________
dropout_3 (Dropout)          (None, 512)               0
_________________________________________________________________
dense_1 (Dense)              (None, 50)                25650
=================================================================
Total params: 8,794,866
Trainable params: 8,793,970
Non-trainable params: 896
Epoch 1/150
22/22 [==============================] - 23s 1s/step - loss: 8.8051 - accuracy: 0.0314 - val_loss: 4.0204 - val_accuracy: 0.0400
Epoch 2/150
22/22 [==============================] - 25s 1s/step - loss: 4.2394 - accuracy: 0.0471 - val_loss: 4.0055 - val_accuracy: 0.0333
Epoch 3/150
22/22 [==============================] - 24s 1s/step - loss: 4.0688 - accuracy: 0.0386 - val_loss: 4.0017 - val_accuracy: 0.0533
Epoch 4/150
22/22 [==============================] - 24s 1s/step - loss: 4.0065 - accuracy: 0.0357 - val_loss: 3.9487 - val_accuracy: 0.0667
Epoch 5/150
22/22 [==============================] - 24s 1s/step - loss: 3.9517 - accuracy: 0.0571 - val_loss: 3.8901 - val_accuracy: 0.0467
Epoch 6/150
22/22 [==============================] - 25s 1s/step - loss: 3.8915 - accuracy: 0.0500 - val_loss: 3.7913 - val_accuracy: 0.0733
Epoch 7/150
22/22 [==============================] - 26s 1s/step - loss: 3.8770 - accuracy: 0.0657 - val_loss: 3.6869 - val_accuracy: 0.0667
Epoch 8/150
22/22 [==============================] - 23s 1s/step - loss: 3.8105 - accuracy: 0.0686 - val_loss: 3.7080 - val_accuracy: 0.0867
Epoch 9/150
22/22 [==============================] - 22s 1s/step - loss: 3.7560 - accuracy: 0.0543 - val_loss: 3.6128 - val_accuracy: 0.1067
Epoch 10/150
22/22 [==============================] - 24s 1s/step - loss: 3.7300 - accuracy: 0.0629 - val_loss: 3.4711 - val_accuracy: 0.0867
Epoch 11/150
22/22 [==============================] - 21s 973ms/step - loss: 3.6430 - accuracy: 0.0771 - val_loss: 3.5142 - val_accuracy: 0.0800
Epoch 12/150
22/22 [==============================] - 26s 1s/step - loss: 3.5921 - accuracy: 0.0771 - val_loss: 3.3307 - val_accuracy: 0.0867
Epoch 13/150
22/22 [==============================] - 23s 1s/step - loss: 3.5252 - accuracy: 0.0829 - val_loss: 3.3249 - val_accuracy: 0.0933
Epoch 14/150
22/22 [==============================] - 23s 1s/step - loss: 3.4942 - accuracy: 0.0729 - val_loss: 3.3082 - val_accuracy: 0.1333
Epoch 15/150
22/22 [==============================] - 24s 1s/step - loss: 3.4751 - accuracy: 0.0800 - val_loss: 3.1981 - val_accuracy: 0.0800
Epoch 16/150
22/22 [==============================] - 23s 1s/step - loss: 3.3935 - accuracy: 0.0786 - val_loss: 3.1661 - val_accuracy: 0.1133
Epoch 17/150
22/22 [==============================] - 23s 1s/step - loss: 3.3485 - accuracy: 0.0800 - val_loss: 3.1378 - val_accuracy: 0.1133
Epoch 18/150
22/22 [==============================] - 19s 857ms/step - loss: 3.3639 - accuracy: 0.0971 - val_loss: 3.2230 - val_accuracy: 0.1267
Epoch 19/150
22/22 [==============================] - 23s 1s/step - loss: 3.3548 - accuracy: 0.0757 - val_loss: 3.1072 - val_accuracy: 0.0933
Epoch 20/150
22/22 [==============================] - 23s 1s/step - loss: 3.2945 - accuracy: 0.0814 - val_loss: 3.0325 - val_accuracy: 0.1600
Epoch 21/150
22/22 [==============================] - 25s 1s/step - loss: 3.2914 - accuracy: 0.0886 - val_loss: 3.1074 - val_accuracy: 0.1400
Epoch 22/150
22/22 [==============================] - 26s 1s/step - loss: 3.2269 - accuracy: 0.0771 - val_loss: 3.0602 - val_accuracy: 0.1333
Epoch 23/150
22/22 [==============================] - 24s 1s/step - loss: 3.2940 - accuracy: 0.0914 - val_loss: 3.3212 - val_accuracy: 0.1200
Epoch 24/150
22/22 [==============================] - 23s 1s/step - loss: 3.1587 - accuracy: 0.1071 - val_loss: 3.0029 - val_accuracy: 0.1333
Epoch 25/150
22/22 [==============================] - 26s 1s/step - loss: 3.2365 - accuracy: 0.0886 - val_loss: 3.0405 - val_accuracy: 0.1733
Epoch 26/150
22/22 [==============================] - 24s 1s/step - loss: 3.2899 - accuracy: 0.1014 - val_loss: 3.0913 - val_accuracy: 0.1600
Epoch 27/150
22/22 [==============================] - 25s 1s/step - loss: 3.1982 - accuracy: 0.0871 - val_loss: 3.0845 - val_accuracy: 0.1533
Epoch 28/150
22/22 [==============================] - 25s 1s/step - loss: 3.1887 - accuracy: 0.0986 - val_loss: 3.0067 - val_accuracy: 0.1733
Epoch 29/150
22/22 [==============================] - 25s 1s/step - loss: 3.1803 - accuracy: 0.0886 - val_loss: 3.0583 - val_accuracy: 0.1467
Epoch 30/150
22/22 [==============================] - 24s 1s/step - loss: 3.1924 - accuracy: 0.0900 - val_loss: 3.1293 - val_accuracy: 0.1067
Epoch 31/150
22/22 [==============================] - 22s 1s/step - loss: 3.0968 - accuracy: 0.1100 - val_loss: 3.1759 - val_accuracy: 0.1400
Epoch 32/150
21/22 [===========================>..] - ETA: 1s - loss: 3.0739 - accuracy: 0.0928
Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
22/22 [==============================] - 23s 1s/step - loss: 3.0814 - accuracy: 0.0914 - val_loss: 3.1410 - val_accuracy: 0.1533
Epoch 33/150
22/22 [==============================] - 22s 992ms/step - loss: 3.0548 - accuracy: 0.1129 - val_loss: 3.1615 - val_accuracy: 0.1267
Epoch 34/150
22/22 [==============================] - 26s 1s/step - loss: 3.0525 - accuracy: 0.0943 - val_loss: 3.0236 - val_accuracy: 0.1800
Epoch 35/150
22/22 [==============================] - 24s 1s/step - loss: 3.0252 - accuracy: 0.1114 - val_loss: 3.1097 - val_accuracy: 0.1467
Epoch 36/150
22/22 [==============================] - 25s 1s/step - loss: 3.0123 - accuracy: 0.1100 - val_loss: 3.2480 - val_accuracy: 0.1467
Epoch 37/150
22/22 [==============================] - 25s 1s/step - loss: 2.9786 - accuracy: 0.1314 - val_loss: 3.2650 - val_accuracy: 0.1600
Epoch 38/150
22/22 [==============================] - 20s 896ms/step - loss: 2.9881 - accuracy: 0.1100 - val_loss: 3.2990 - val_accuracy: 0.1733
Epoch 39/150
22/22 [==============================] - 26s 1s/step - loss: 2.9535 - accuracy: 0.1443 - val_loss: 3.0100 - val_accuracy: 0.1733
Epoch 40/150
21/22 [===========================>..] - ETA: 1s - loss: 2.9652 - accuracy: 0.1243
Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
22/22 [==============================] - 25s 1s/step - loss: 2.9671 - accuracy: 0.1214 - val_loss: 3.1517 - val_accuracy: 0.1667
Epoch 41/150
22/22 [==============================] - 23s 1s/step - loss: 2.9285 - accuracy: 0.1214 - val_loss: 3.0991 - val_accuracy: 0.1533
Epoch 42/150
22/22 [==============================] - 23s 1s/step - loss: 2.9559 - accuracy: 0.1286 - val_loss: 3.0962 - val_accuracy: 0.1867
Epoch 43/150
22/22 [==============================] - 26s 1s/step - loss: 2.8738 - accuracy: 0.1514 - val_loss: 3.1393 - val_accuracy: 0.1533
Epoch 44/150
22/22 [==============================] - 24s 1s/step - loss: 2.9146 - accuracy: 0.1429 - val_loss: 3.1471 - val_accuracy: 0.1933
Epoch 45/150
22/22 [==============================] - 25s 1s/step - loss: 2.9144 - accuracy: 0.1386 - val_loss: 3.1574 - val_accuracy: 0.1933
Epoch 46/150
22/22 [==============================] - 22s 1s/step - loss: 2.9162 - accuracy: 0.1386 - val_loss: 3.1464 - val_accuracy: 0.2400
Epoch 47/150
22/22 [==============================] - 23s 1s/step - loss: 2.8670 - accuracy: 0.1257 - val_loss: 3.2341 - val_accuracy: 0.2067
Epoch 48/150
21/22 [===========================>..] - ETA: 1s - loss: 2.8925 - accuracy: 0.1512
Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
22/22 [==============================] - 25s 1s/step - loss: 2.8984 - accuracy: 0.1500 - val_loss: 3.0419 - val_accuracy: 0.2000
Epoch 49/150
22/22 [==============================] - 24s 1s/step - loss: 2.8940 - accuracy: 0.1529 - val_loss: 3.0185 - val_accuracy: 0.2067
Epoch 50/150
22/22 [==============================] - 25s 1s/step - loss: 2.8278 - accuracy: 0.1714 - val_loss: 3.0742 - val_accuracy: 0.2533
Epoch 51/150
22/22 [==============================] - 24s 1s/step - loss: 2.8165 - accuracy: 0.1629 - val_loss: 3.1712 - val_accuracy: 0.2667
Epoch 52/150
22/22 [==============================] - 24s 1s/step - loss: 2.8614 - accuracy: 0.1429 - val_loss: 3.1185 - val_accuracy: 0.2467
Epoch 53/150
22/22 [==============================] - 21s 935ms/step - loss: 2.7928 - accuracy: 0.1871 - val_loss: 3.0773 - val_accuracy: 0.2400
Epoch 54/150
22/22 [==============================] - 21s 969ms/step - loss: 2.7923 - accuracy: 0.1543 - val_loss: 3.0483 - val_accuracy: 0.2067
Epoch 55/150
22/22 [==============================] - 22s 1s/step - loss: 2.8127 - accuracy: 0.1600 - val_loss: 3.0102 - val_accuracy: 0.2200
Epoch 56/150
21/22 [===========================>..] - ETA: 1s - loss: 2.7657 - accuracy: 0.1722
Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
22/22 [==============================] - 22s 1s/step - loss: 2.7616 - accuracy: 0.1714 - val_loss: 3.0235 - val_accuracy: 0.2400
Epoch 57/150
22/22 [==============================] - 28s 1s/step - loss: 2.7937 - accuracy: 0.1586 - val_loss: 3.0196 - val_accuracy: 0.2600
Epoch 58/150
22/22 [==============================] - 27s 1s/step - loss: 2.7928 - accuracy: 0.1629 - val_loss: 3.0303 - val_accuracy: 0.2667
Epoch 59/150
22/22 [==============================] - 21s 956ms/step - loss: 2.7523 - accuracy: 0.1743 - val_loss: 3.0311 - val_accuracy: 0.2667
Epoch 60/150
22/22 [==============================] - 22s 1s/step - loss: 2.8268 - accuracy: 0.1714 - val_loss: 3.0279 - val_accuracy: 0.2600
Epoch 61/150
22/22 [==============================] - 24s 1s/step - loss: 2.7453 - accuracy: 0.1743 - val_loss: 3.0575 - val_accuracy: 0.2733
Epoch 62/150
22/22 [==============================] - 23s 1s/step - loss: 2.7852 - accuracy: 0.1686 - val_loss: 3.0310 - val_accuracy: 0.2733
Epoch 63/150
22/22 [==============================] - 23s 1s/step - loss: 2.7340 - accuracy: 0.1771 - val_loss: 3.0235 - val_accuracy: 0.2800
Epoch 64/150
21/22 [===========================>..] - ETA: 1s - loss: 2.6818 - accuracy: 0.1901
Epoch 00064: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
22/22 [==============================] - 23s 1s/step - loss: 2.6826 - accuracy: 0.1857 - val_loss: 3.0485 - val_accuracy: 0.2667
Epoch 65/150
22/22 [==============================] - 23s 1s/step - loss: 2.7181 - accuracy: 0.1929 - val_loss: 3.0692 - val_accuracy: 0.2533
Epoch 66/150
22/22 [==============================] - 23s 1s/step - loss: 2.7448 - accuracy: 0.1829 - val_loss: 3.0606 - val_accuracy: 0.2533
Epoch 67/150
22/22 [==============================] - 23s 1s/step - loss: 2.7065 - accuracy: 0.1886 - val_loss: 3.0327 - val_accuracy: 0.2467
Epoch 68/150
22/22 [==============================] - 25s 1s/step - loss: 2.7800 - accuracy: 0.1857 - val_loss: 3.0326 - val_accuracy: 0.2733
Epoch 69/150
22/22 [==============================] - 25s 1s/step - loss: 2.7553 - accuracy: 0.1729 - val_loss: 3.0499 - val_accuracy: 0.2733
Epoch 70/150
22/22 [==============================] - 21s 973ms/step - loss: 2.7595 - accuracy: 0.1814 - val_loss: 3.0539 - val_accuracy: 0.2733
Epoch 71/150
22/22 [==============================] - 25s 1s/step - loss: 2.7369 - accuracy: 0.1786 - val_loss: 3.0623 - val_accuracy: 0.2667
Epoch 72/150
21/22 [===========================>..] - ETA: 1s - loss: 2.7139 - accuracy: 0.2036
Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.
22/22 [==============================] - 23s 1s/step - loss: 2.7184 - accuracy: 0.2029 - val_loss: 3.0873 - val_accuracy: 0.2267
Epoch 73/150
22/22 [==============================] - 24s 1s/step - loss: 2.7131 - accuracy: 0.1829 - val_loss: 3.0682 - val_accuracy: 0.2400
Epoch 74/150
22/22 [==============================] - 26s 1s/step - loss: 2.6909 - accuracy: 0.1657 - val_loss: 3.0630 - val_accuracy: 0.2467
Epoch 75/150
22/22 [==============================] - 24s 1s/step - loss: 2.7600 - accuracy: 0.1757 - val_loss: 3.0583 - val_accuracy: 0.2600
Epoch 76/150
22/22 [==============================] - 21s 977ms/step - loss: 2.7443 - accuracy: 0.1857 - val_loss: 3.0446 - val_accuracy: 0.2667
Epoch 77/150
22/22 [==============================] - 24s 1s/step - loss: 2.7762 - accuracy: 0.1714 - val_loss: 3.0399 - val_accuracy: 0.2533
Epoch 78/150
22/22 [==============================] - 25s 1s/step - loss: 2.7496 - accuracy: 0.1757 - val_loss: 3.0541 - val_accuracy: 0.2600
[DEBUG] 模型训练完成

=== 正在训练 2dcnn ===
[DEBUG] X_train原始形状: (700, 64, 64, 16)
[DEBUG] y_train形状: (700,)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_3 (Conv2D)            (None, 64, 64, 64)        9280
_________________________________________________________________
batch_normalization_3 (Batch (None, 64, 64, 64)        256
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 32, 32, 64)        0
_________________________________________________________________
dropout_4 (Dropout)          (None, 32, 32, 64)        0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 32, 32, 128)       73856
_________________________________________________________________
batch_normalization_4 (Batch (None, 32, 32, 128)       512
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 16, 16, 128)       0
_________________________________________________________________
dropout_5 (Dropout)          (None, 16, 16, 128)       0
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 16, 16, 256)       295168
_________________________________________________________________
batch_normalization_5 (Batch (None, 16, 16, 256)       1024
_________________________________________________________________
global_average_pooling2d (Gl (None, 256)               0
_________________________________________________________________
dense_2 (Dense)              (None, 512)               131584
_________________________________________________________________
dropout_6 (Dropout)          (None, 512)               0
_________________________________________________________________
dense_3 (Dense)              (None, 50)                25650
=================================================================
Total params: 537,330
Trainable params: 536,434
Non-trainable params: 896
_________________________________________________________________

Epoch 1/150
22/22 [==============================] - 17s 766ms/step - loss: 3.9197 - accuracy: 0.0443 - val_loss: 3.9506 - val_accuracy: 0.0200
Epoch 2/150
22/22 [==============================] - 17s 758ms/step - loss: 3.5051 - accuracy: 0.0714 - val_loss: 3.6342 - val_accuracy: 0.0467
Epoch 3/150
22/22 [==============================] - 24s 1s/step - loss: 3.3142 - accuracy: 0.0943 - val_loss: 3.6493 - val_accuracy: 0.0400
Epoch 4/150
22/22 [==============================] - 23s 1s/step - loss: 3.1556 - accuracy: 0.1057 - val_loss: 3.4788 - val_accuracy: 0.0667
Epoch 5/150
22/22 [==============================] - 21s 958ms/step - loss: 2.9508 - accuracy: 0.1371 - val_loss: 3.2997 - val_accuracy: 0.1400
Epoch 6/150
22/22 [==============================] - 22s 992ms/step - loss: 2.8343 - accuracy: 0.1771 - val_loss: 3.1678 - val_accuracy: 0.1200
Epoch 7/150
22/22 [==============================] - 24s 1s/step - loss: 2.7576 - accuracy: 0.1786 - val_loss: 3.3677 - val_accuracy: 0.0867
Epoch 8/150
22/22 [==============================] - 18s 832ms/step - loss: 2.6367 - accuracy: 0.2129 - val_loss: 3.4018 - val_accuracy: 0.1200
Epoch 9/150
22/22 [==============================] - 23s 1s/step - loss: 2.5673 - accuracy: 0.2386 - val_loss: 3.0206 - val_accuracy: 0.1600
Epoch 10/150
22/22 [==============================] - 14s 648ms/step - loss: 2.4796 - accuracy: 0.2443 - val_loss: 3.0539 - val_accuracy: 0.1800
Epoch 11/150
22/22 [==============================] - 16s 726ms/step - loss: 2.3896 - accuracy: 0.2586 - val_loss: 3.0245 - val_accuracy: 0.1933
Epoch 12/150
22/22 [==============================] - 19s 883ms/step - loss: 2.2952 - accuracy: 0.3000 - val_loss: 3.1961 - val_accuracy: 0.1400
Epoch 13/150
22/22 [==============================] - 19s 864ms/step - loss: 2.2192 - accuracy: 0.3457 - val_loss: 2.9512 - val_accuracy: 0.2333
Epoch 14/150
22/22 [==============================] - 18s 802ms/step - loss: 2.1484 - accuracy: 0.3500 - val_loss: 2.8025 - val_accuracy: 0.2000
Epoch 15/150
22/22 [==============================] - 18s 819ms/step - loss: 2.1153 - accuracy: 0.3457 - val_loss: 3.5577 - val_accuracy: 0.1533
Epoch 16/150
22/22 [==============================] - 16s 718ms/step - loss: 1.9898 - accuracy: 0.3857 - val_loss: 3.0607 - val_accuracy: 0.2000
Epoch 17/150
22/22 [==============================] - 22s 984ms/step - loss: 1.8909 - accuracy: 0.4386 - val_loss: 3.3913 - val_accuracy: 0.2000
Epoch 18/150
22/22 [==============================] - 21s 955ms/step - loss: 1.8676 - accuracy: 0.4186 - val_loss: 3.2852 - val_accuracy: 0.2200
Epoch 19/150
22/22 [==============================] - 21s 964ms/step - loss: 1.8125 - accuracy: 0.4557 - val_loss: 3.0537 - val_accuracy: 0.2067
Epoch 20/150
22/22 [==============================] - 22s 1s/step - loss: 1.7213 - accuracy: 0.4829 - val_loss: 3.8951 - val_accuracy: 0.1733
Epoch 21/150
22/22 [==============================] - 22s 983ms/step - loss: 1.6503 - accuracy: 0.4971 - val_loss: 3.5571 - val_accuracy: 0.1733
Epoch 22/150
21/22 [===========================>..] - ETA: 0s - loss: 1.6415 - accuracy: 0.4792
Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
22/22 [==============================] - 16s 743ms/step - loss: 1.6212 - accuracy: 0.4857 - val_loss: 4.4031 - val_accuracy: 0.1333
Epoch 23/150
22/22 [==============================] - 19s 882ms/step - loss: 1.4591 - accuracy: 0.5814 - val_loss: 3.5726 - val_accuracy: 0.2000
Epoch 24/150
22/22 [==============================] - 26s 1s/step - loss: 1.4013 - accuracy: 0.6000 - val_loss: 4.1984 - val_accuracy: 0.1400
Epoch 25/150
22/22 [==============================] - 16s 709ms/step - loss: 1.3267 - accuracy: 0.6386 - val_loss: 3.3199 - val_accuracy: 0.2400
Epoch 26/150
22/22 [==============================] - 20s 909ms/step - loss: 1.3280 - accuracy: 0.6157 - val_loss: 3.0117 - val_accuracy: 0.2600
Epoch 27/150
22/22 [==============================] - 23s 1s/step - loss: 1.2911 - accuracy: 0.6286 - val_loss: 3.4467 - val_accuracy: 0.2200
Epoch 28/150
22/22 [==============================] - 21s 969ms/step - loss: 1.2314 - accuracy: 0.6314 - val_loss: 3.7396 - val_accuracy: 0.1933
Epoch 29/150
22/22 [==============================] - 20s 929ms/step - loss: 1.2113 - accuracy: 0.6586 - val_loss: 3.6887 - val_accuracy: 0.2267
Epoch 30/150
21/22 [===========================>..] - ETA: 1s - loss: 1.1869 - accuracy: 0.6722
Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
22/22 [==============================] - 23s 1s/step - loss: 1.1914 - accuracy: 0.6700 - val_loss: 3.5564 - val_accuracy: 0.2200
Epoch 31/150
22/22 [==============================] - 23s 1s/step - loss: 1.1152 - accuracy: 0.6943 - val_loss: 3.6450 - val_accuracy: 0.2800
Epoch 32/150
22/22 [==============================] - 23s 1s/step - loss: 1.0614 - accuracy: 0.7200 - val_loss: 3.6194 - val_accuracy: 0.2467
Epoch 33/150
22/22 [==============================] - 21s 960ms/step - loss: 1.0577 - accuracy: 0.7257 - val_loss: 3.4865 - val_accuracy: 0.2333
Epoch 34/150
22/22 [==============================] - 15s 689ms/step - loss: 1.0259 - accuracy: 0.7171 - val_loss: 3.5475 - val_accuracy: 0.2333
Epoch 35/150
22/22 [==============================] - 19s 868ms/step - loss: 1.0646 - accuracy: 0.7214 - val_loss: 3.4818 - val_accuracy: 0.2533
Epoch 36/150
22/22 [==============================] - 20s 931ms/step - loss: 1.0255 - accuracy: 0.7143 - val_loss: 3.6953 - val_accuracy: 0.2467
Epoch 37/150
22/22 [==============================] - 19s 875ms/step - loss: 0.9719 - accuracy: 0.7414 - val_loss: 3.4369 - val_accuracy: 0.2733
Epoch 38/150
21/22 [===========================>..] - ETA: 1s - loss: 0.9434 - accuracy: 0.7485
Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
22/22 [==============================] - 22s 1s/step - loss: 0.9531 - accuracy: 0.7500 - val_loss: 3.4997 - val_accuracy: 0.2667
Epoch 39/150
22/22 [==============================] - 23s 1s/step - loss: 0.9810 - accuracy: 0.7286 - val_loss: 3.6096 - val_accuracy: 0.2600
Epoch 40/150
22/22 [==============================] - 19s 860ms/step - loss: 0.9371 - accuracy: 0.7629 - val_loss: 3.4382 - val_accuracy: 0.2733
Epoch 41/150
22/22 [==============================] - 20s 924ms/step - loss: 0.9299 - accuracy: 0.7614 - val_loss: 3.5894 - val_accuracy: 0.2467
Epoch 42/150
22/22 [==============================] - 22s 1s/step - loss: 0.9164 - accuracy: 0.7529 - val_loss: 3.5761 - val_accuracy: 0.2600
Epoch 43/150
22/22 [==============================] - 22s 1s/step - loss: 0.8700 - accuracy: 0.7871 - val_loss: 3.4150 - val_accuracy: 0.2867
Epoch 44/150
22/22 [==============================] - 23s 1s/step - loss: 0.8847 - accuracy: 0.7771 - val_loss: 3.4506 - val_accuracy: 0.2933
Epoch 45/150
22/22 [==============================] - 21s 955ms/step - loss: 0.8696 - accuracy: 0.7671 - val_loss: 3.4313 - val_accuracy: 0.2933
Epoch 46/150
21/22 [===========================>..] - ETA: 1s - loss: 0.8496 - accuracy: 0.7904
Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
22/22 [==============================] - 23s 1s/step - loss: 0.8494 - accuracy: 0.7886 - val_loss: 3.4491 - val_accuracy: 0.2933
Epoch 47/150
22/22 [==============================] - 20s 893ms/step - loss: 0.8488 - accuracy: 0.7900 - val_loss: 3.3730 - val_accuracy: 0.3000
Epoch 48/150
22/22 [==============================] - 24s 1s/step - loss: 0.8510 - accuracy: 0.7814 - val_loss: 3.4285 - val_accuracy: 0.3067
Epoch 49/150
22/22 [==============================] - 20s 904ms/step - loss: 0.8751 - accuracy: 0.7829 - val_loss: 3.5577 - val_accuracy: 0.2800
Epoch 50/150
22/22 [==============================] - 15s 699ms/step - loss: 0.8141 - accuracy: 0.8029 - val_loss: 3.5006 - val_accuracy: 0.2867
Epoch 51/150
22/22 [==============================] - 16s 735ms/step - loss: 0.8656 - accuracy: 0.7729 - val_loss: 3.4555 - val_accuracy: 0.3000
Epoch 52/150
22/22 [==============================] - 22s 980ms/step - loss: 0.8191 - accuracy: 0.8086 - val_loss: 3.5833 - val_accuracy: 0.2800
Epoch 53/150
22/22 [==============================] - 20s 914ms/step - loss: 0.8337 - accuracy: 0.7957 - val_loss: 3.5015 - val_accuracy: 0.2933
Epoch 54/150
21/22 [===========================>..] - ETA: 0s - loss: 0.8188 - accuracy: 0.8159
Epoch 00054: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
22/22 [==============================] - 22s 1s/step - loss: 0.8227 - accuracy: 0.8086 - val_loss: 3.4813 - val_accuracy: 0.2933
Epoch 55/150
22/22 [==============================] - 25s 1s/step - loss: 0.8089 - accuracy: 0.8029 - val_loss: 3.4928 - val_accuracy: 0.2933
Epoch 56/150
22/22 [==============================] - 16s 743ms/step - loss: 0.8243 - accuracy: 0.7914 - val_loss: 3.5404 - val_accuracy: 0.3000
Epoch 57/150
22/22 [==============================] - 23s 1s/step - loss: 0.8053 - accuracy: 0.8100 - val_loss: 3.5542 - val_accuracy: 0.2867
Epoch 58/150
22/22 [==============================] - 20s 895ms/step - loss: 0.8212 - accuracy: 0.7814 - val_loss: 3.4780 - val_accuracy: 0.3000
Epoch 59/150
22/22 [==============================] - 16s 717ms/step - loss: 0.8047 - accuracy: 0.8100 - val_loss: 3.4826 - val_accuracy: 0.2933
Epoch 60/150
22/22 [==============================] - 18s 808ms/step - loss: 0.8044 - accuracy: 0.8143 - val_loss: 3.5166 - val_accuracy: 0.2933
Epoch 61/150
22/22 [==============================] - 15s 679ms/step - loss: 0.8275 - accuracy: 0.8057 - val_loss: 3.5204 - val_accuracy: 0.2933
Epoch 62/150
21/22 [===========================>..] - ETA: 0s - loss: 0.8031 - accuracy: 0.8024
Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.
22/22 [==============================] - 20s 906ms/step - loss: 0.8092 - accuracy: 0.7986 - val_loss: 3.5917 - val_accuracy: 0.2800
Epoch 63/150
22/22 [==============================] - 14s 616ms/step - loss: 0.8089 - accuracy: 0.7914 - val_loss: 3.5403 - val_accuracy: 0.2867
[DEBUG] 模型训练完成

=== 正在训练 lstm_model ===
[DEBUG] X_train原始形状: (700, 64, 64, 16)
[DEBUG] y_train形状: (700,)
[DEBUG] 时序模型维度检查 h=64, w=64, c=16
[DEBUG] 总特征数计算: 64*64*16=65536
[DEBUG] 输入形状设置: (16, 4096)
[DEBUG] 预处理后形状 - 训练集: (700, 16, 4096), 验证集: (150, 16, 4096)
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
lstm (LSTM)                  (None, 128)               2163200
_________________________________________________________________
dense_4 (Dense)              (None, 64)                8256
_________________________________________________________________
dense_5 (Dense)              (None, 50)                3250
=================================================================
Total params: 2,174,706
Trainable params: 2,174,706
Non-trainable params: 0
_________________________________________________________________
Train on 700 samples, validate on 150 samples
Epoch 1/150
672/700 [===========================>..] - ETA: 0s - loss: 3.9090 - accuracy: 0.04172025-05-11 15:07:37.074726: W 
700/700 [==============================] - 5s 8ms/sample - loss: 3.9054 - accuracy: 0.0414 - val_loss: 3.8293 - val_accuracy: 0.0667
Epoch 2/150
700/700 [==============================] - 2s 3ms/sample - loss: 3.6834 - accuracy: 0.0829 - val_loss: 3.7591 - val_accuracy: 0.0733
Epoch 3/150
700/700 [==============================] - 2s 3ms/sample - loss: 3.4341 - accuracy: 0.1929 - val_loss: 3.6539 - val_accuracy: 0.1133
Epoch 4/150
700/700 [==============================] - 2s 3ms/sample - loss: 3.1527 - accuracy: 0.2686 - val_loss: 3.5562 - val_accuracy: 0.0933
Epoch 5/150
700/700 [==============================] - 2s 3ms/sample - loss: 2.8270 - accuracy: 0.3543 - val_loss: 3.4280 - val_accuracy: 0.1867
Epoch 6/150
700/700 [==============================] - 2s 3ms/sample - loss: 2.5145 - accuracy: 0.4343 - val_loss: 3.3440 - val_accuracy: 0.1733
Epoch 7/150
700/700 [==============================] - 2s 3ms/sample - loss: 2.2444 - accuracy: 0.4829 - val_loss: 3.2415 - val_accuracy: 0.1800
Epoch 8/150
700/700 [==============================] - 2s 3ms/sample - loss: 1.9765 - accuracy: 0.5200 - val_loss: 3.2264 - val_accuracy: 0.1800
Epoch 9/150
700/700 [==============================] - 2s 3ms/sample - loss: 1.7890 - accuracy: 0.5500 - val_loss: 3.1324 - val_accuracy: 0.1867
Epoch 10/150
700/700 [==============================] - 2s 3ms/sample - loss: 1.6021 - accuracy: 0.6043 - val_loss: 3.0302 - val_accuracy: 0.2067
Epoch 11/150
700/700 [==============================] - 2s 3ms/sample - loss: 1.4588 - accuracy: 0.6500 - val_loss: 3.0603 - val_accuracy: 0.2133
Epoch 12/150
700/700 [==============================] - 2s 3ms/sample - loss: 1.3329 - accuracy: 0.6786 - val_loss: 3.0665 - val_accuracy: 0.2067
Epoch 13/150
700/700 [==============================] - 2s 4ms/sample - loss: 1.2217 - accuracy: 0.7114 - val_loss: 3.0732 - val_accuracy: 0.2400
Epoch 14/150
700/700 [==============================] - 2s 3ms/sample - loss: 1.1056 - accuracy: 0.7429 - val_loss: 2.9954 - val_accuracy: 0.2067
Epoch 15/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.9671 - accuracy: 0.8071 - val_loss: 3.1162 - val_accuracy: 0.2400
Epoch 16/150
700/700 [==============================] - 3s 4ms/sample - loss: 0.8774 - accuracy: 0.8286 - val_loss: 3.1112 - val_accuracy: 0.2133
Epoch 17/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.7723 - accuracy: 0.8714 - val_loss: 3.0805 - val_accuracy: 0.2133
Epoch 18/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.6660 - accuracy: 0.9014 - val_loss: 3.1852 - val_accuracy: 0.2533
Epoch 19/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.5967 - accuracy: 0.9100 - val_loss: 3.1937 - val_accuracy: 0.2333
Epoch 20/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.5011 - accuracy: 0.9400 - val_loss: 3.2105 - val_accuracy: 0.2533
Epoch 21/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.4302 - accuracy: 0.9643 - val_loss: 3.2111 - val_accuracy: 0.2267
Epoch 22/150
672/700 [===========================>..] - ETA: 0s - loss: 0.3957 - accuracy: 0.9688
Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
700/700 [==============================] - 2s 3ms/sample - loss: 0.3980 - accuracy: 0.9700 - val_loss: 3.2302 - val_accuracy: 0.2267
Epoch 23/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.3254 - accuracy: 0.9786 - val_loss: 3.2638 - val_accuracy: 0.2467
Epoch 24/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.2797 - accuracy: 0.9857 - val_loss: 3.2545 - val_accuracy: 0.2533
Epoch 25/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.2559 - accuracy: 0.9929 - val_loss: 3.3153 - val_accuracy: 0.2533
Epoch 26/150
700/700 [==============================] - 3s 4ms/sample - loss: 0.2358 - accuracy: 0.9929 - val_loss: 3.3040 - val_accuracy: 0.2400
Epoch 27/150
700/700 [==============================] - 3s 4ms/sample - loss: 0.2195 - accuracy: 0.9971 - val_loss: 3.3034 - val_accuracy: 0.2333
Epoch 28/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.2024 - accuracy: 0.9971 - val_loss: 3.3460 - val_accuracy: 0.2200
Epoch 29/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.1905 - accuracy: 0.9986 - val_loss: 3.3559 - val_accuracy: 0.2267
Epoch 30/150
672/700 [===========================>..] - ETA: 0s - loss: 0.1755 - accuracy: 1.0000
Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
700/700 [==============================] - 2s 3ms/sample - loss: 0.1759 - accuracy: 1.0000 - val_loss: 3.3698 - val_accuracy: 0.2133
Epoch 31/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.1609 - accuracy: 1.0000 - val_loss: 3.3926 - val_accuracy: 0.2000
Epoch 32/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.1542 - accuracy: 1.0000 - val_loss: 3.3958 - val_accuracy: 0.2067
Epoch 33/150
700/700 [==============================] - 2s 3ms/sample - loss: 0.1488 - accuracy: 1.0000 - val_loss: 3.4042 - val_accuracy: 0.2000
[DEBUG] 模型训练完成
=== 正在训练 1dcnn_lstm ===
[DEBUG] X_train原始形状: (700, 64, 64, 16)
[DEBUG] y_train形状: (700,)
[DEBUG] 时序模型维度检查 h=64, w=64, c=16
[DEBUG] 总特征数计算: 64*64*16=65536
[DEBUG] 输入形状设置: (16, 4096)
[DEBUG] 预处理后形状 - 训练集: (700, 16, 4096), 验证集: (150, 16, 4096)
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv1d (Conv1D)              (None, 16, 64)            786496
_________________________________________________________________
batch_normalization_6 (Batch (None, 16, 64)            256
_________________________________________________________________
dropout_7 (Dropout)          (None, 16, 64)            0
_________________________________________________________________
lstm_1 (LSTM)                (None, 128)               98816
_________________________________________________________________
dense_6 (Dense)              (None, 64)                8256
_________________________________________________________________
dense_7 (Dense)              (None, 50)                3250
=================================================================
Total params: 897,074
Trainable params: 896,946
Non-trainable params: 128
_________________________________________________________________
Train on 700 samples, validate on 150 samples
Epoch 1/150
672/700 [===========================>..] - ETA: 0s - loss: 3.8825 - accuracy: 0.03122025-05-11 15:08:56.843740: W 
700/700 [==============================] - 5s 7ms/sample - loss: 3.8810 - accuracy: 0.0329 - val_loss: 3.9048 - val_accuracy: 0.0067
Epoch 2/150
700/700 [==============================] - 1s 2ms/sample - loss: 3.5521 - accuracy: 0.1600 - val_loss: 3.8387 - val_accuracy: 0.0533
Epoch 3/150
700/700 [==============================] - 1s 2ms/sample - loss: 3.0876 - accuracy: 0.2457 - val_loss: 3.5806 - val_accuracy: 0.1067
Epoch 4/150
700/700 [==============================] - 1s 2ms/sample - loss: 2.5117 - accuracy: 0.3943 - val_loss: 3.6804 - val_accuracy: 0.1067
Epoch 5/150
700/700 [==============================] - 1s 2ms/sample - loss: 1.9483 - accuracy: 0.5143 - val_loss: 3.4666 - val_accuracy: 0.1333
Epoch 6/150
700/700 [==============================] - 1s 2ms/sample - loss: 1.5414 - accuracy: 0.6114 - val_loss: 3.9885 - val_accuracy: 0.1400
Epoch 7/150
700/700 [==============================] - 1s 2ms/sample - loss: 1.2622 - accuracy: 0.6914 - val_loss: 3.2474 - val_accuracy: 0.1867
Epoch 8/150
700/700 [==============================] - 1s 2ms/sample - loss: 1.0666 - accuracy: 0.7300 - val_loss: 3.6528 - val_accuracy: 0.1733
Epoch 9/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.9225 - accuracy: 0.7614 - val_loss: 3.3102 - val_accuracy: 0.1867
Epoch 10/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.8218 - accuracy: 0.7957 - val_loss: 3.5022 - val_accuracy: 0.1867
Epoch 11/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.7704 - accuracy: 0.7957 - val_loss: 3.2937 - val_accuracy: 0.2133
Epoch 12/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.6851 - accuracy: 0.8257 - val_loss: 3.4707 - val_accuracy: 0.2133
Epoch 13/150
700/700 [==============================] - 2s 2ms/sample - loss: 0.6573 - accuracy: 0.8257 - val_loss: 3.6980 - val_accuracy: 0.2067
Epoch 14/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.6433 - accuracy: 0.8271 - val_loss: 3.9970 - val_accuracy: 0.1867
Epoch 15/150
672/700 [===========================>..] - ETA: 0s - loss: 0.5791 - accuracy: 0.8363
Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
700/700 [==============================] - 1s 2ms/sample - loss: 0.5769 - accuracy: 0.8386 - val_loss: 3.5809 - val_accuracy: 0.2133
Epoch 16/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.4996 - accuracy: 0.8757 - val_loss: 3.6198 - val_accuracy: 0.2600
Epoch 17/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.4353 - accuracy: 0.8786 - val_loss: 3.7280 - val_accuracy: 0.2667
Epoch 18/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.4098 - accuracy: 0.8857 - val_loss: 3.8033 - val_accuracy: 0.2267
Epoch 19/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.3885 - accuracy: 0.8914 - val_loss: 3.7592 - val_accuracy: 0.2533
Epoch 20/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.3670 - accuracy: 0.8943 - val_loss: 3.7463 - val_accuracy: 0.2267
Epoch 21/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.3585 - accuracy: 0.9029 - val_loss: 3.8565 - val_accuracy: 0.2267
Epoch 22/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.3707 - accuracy: 0.8900 - val_loss: 3.7990 - val_accuracy: 0.2133
Epoch 23/150
640/700 [==========================>...] - ETA: 0s - loss: 0.3605 - accuracy: 0.9094
Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
700/700 [==============================] - 1s 2ms/sample - loss: 0.3478 - accuracy: 0.9114 - val_loss: 3.7337 - val_accuracy: 0.2067
Epoch 24/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.2811 - accuracy: 0.9214 - val_loss: 3.8025 - val_accuracy: 0.2267
Epoch 25/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.2474 - accuracy: 0.9371 - val_loss: 3.9951 - val_accuracy: 0.2267
Epoch 26/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.2090 - accuracy: 0.9471 - val_loss: 3.8841 - val_accuracy: 0.2267
Epoch 27/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.2024 - accuracy: 0.9600 - val_loss: 3.8166 - val_accuracy: 0.2333
Epoch 28/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.2106 - accuracy: 0.9486 - val_loss: 3.7849 - val_accuracy: 0.2933
Epoch 29/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.1910 - accuracy: 0.9657 - val_loss: 3.9072 - val_accuracy: 0.2733
Epoch 30/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.2111 - accuracy: 0.9443 - val_loss: 3.9267 - val_accuracy: 0.2600
Epoch 31/150
640/700 [==========================>...] - ETA: 0s - loss: 0.1631 - accuracy: 0.9703
Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
700/700 [==============================] - 1s 2ms/sample - loss: 0.1690 - accuracy: 0.9657 - val_loss: 3.9507 - val_accuracy: 0.2667
Epoch 32/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.1522 - accuracy: 0.9700 - val_loss: 3.9621 - val_accuracy: 0.2533
Epoch 33/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.1327 - accuracy: 0.9714 - val_loss: 3.9489 - val_accuracy: 0.2600
Epoch 34/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.1384 - accuracy: 0.9671 - val_loss: 3.9287 - val_accuracy: 0.2600
Epoch 35/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.1440 - accuracy: 0.9686 - val_loss: 3.8990 - val_accuracy: 0.2667
Epoch 36/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.1192 - accuracy: 0.9814 - val_loss: 4.0226 - val_accuracy: 0.2867
Epoch 37/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.1169 - accuracy: 0.9743 - val_loss: 3.9808 - val_accuracy: 0.2733
Epoch 38/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.1051 - accuracy: 0.9843 - val_loss: 4.0469 - val_accuracy: 0.2600
Epoch 39/150
672/700 [===========================>..] - ETA: 0s - loss: 0.1117 - accuracy: 0.9762
Epoch 00039: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
700/700 [==============================] - 1s 2ms/sample - loss: 0.1099 - accuracy: 0.9771 - val_loss: 3.9822 - val_accuracy: 0.2667
Epoch 40/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.0989 - accuracy: 0.9814 - val_loss: 4.0096 - val_accuracy: 0.2867
Epoch 41/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.1038 - accuracy: 0.9757 - val_loss: 4.0150 - val_accuracy: 0.2800
Epoch 42/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.0838 - accuracy: 0.9814 - val_loss: 4.0743 - val_accuracy: 0.2600
Epoch 43/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.0952 - accuracy: 0.9800 - val_loss: 4.0496 - val_accuracy: 0.2733
[DEBUG] 模型训练完成

=== 正在训练 1dcnn_pool_lstm ===
[DEBUG] X_train原始形状: (700, 64, 64, 16)
[DEBUG] y_train形状: (700,)
[DEBUG] 时序模型维度检查 h=64, w=64, c=16
[DEBUG] 总特征数计算: 64*64*16=65536
[DEBUG] 输入形状设置: (16, 4096)
[DEBUG] 预处理后形状 - 训练集: (700, 16, 4096), 验证集: (150, 16, 4096)
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv1d_1 (Conv1D)            (None, 16, 64)            786496
_________________________________________________________________
batch_normalization_7 (Batch (None, 16, 64)            256
_________________________________________________________________
max_pooling1d (MaxPooling1D) (None, 8, 64)             0
_________________________________________________________________
dropout_8 (Dropout)          (None, 8, 64)             0
_________________________________________________________________
lstm_2 (LSTM)                (None, 128)               98816
_________________________________________________________________
dense_8 (Dense)              (None, 64)                8256
_________________________________________________________________
dense_9 (Dense)              (None, 50)                3250
=================================================================
Total params: 897,074
Trainable params: 896,946
Non-trainable params: 128
_________________________________________________________________
Train on 700 samples, validate on 150 samples
Epoch 1/150
672/700 [===========================>..] - ETA: 0s - loss: 3.8688 - accuracy: 0.04612025-05-11 15:09:55.519385: W ====] - 5s 7ms/sample - loss: 3.8664 - accuracy: 0.0471 - val_loss: 3.8640 - val_accuracy: 0.0400
Epoch 2/150
700/700 [==============================] - 1s 1ms/sample - loss: 3.5542 - accuracy: 0.1729 - val_loss: 3.7083 - val_accuracy: 0.0867
Epoch 3/150
700/700 [==============================] - 1s 1ms/sample - loss: 3.1248 - accuracy: 0.2671 - val_loss: 3.5012 - val_accuracy: 0.1000
Epoch 4/150
700/700 [==============================] - 1s 1ms/sample - loss: 2.5728 - accuracy: 0.3629 - val_loss: 3.3125 - val_accuracy: 0.1800
Epoch 5/150
700/700 [==============================] - 1s 2ms/sample - loss: 2.0621 - accuracy: 0.4814 - val_loss: 3.1019 - val_accuracy: 0.1800
Epoch 6/150
700/700 [==============================] - 1s 1ms/sample - loss: 1.6653 - accuracy: 0.5957 - val_loss: 3.5552 - val_accuracy: 0.1400
Epoch 7/150
700/700 [==============================] - 1s 1ms/sample - loss: 1.3664 - accuracy: 0.6714 - val_loss: 2.8316 - val_accuracy: 0.2400
Epoch 8/150
700/700 [==============================] - 1s 2ms/sample - loss: 1.1302 - accuracy: 0.7257 - val_loss: 3.0653 - val_accuracy: 0.2400
Epoch 9/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.9800 - accuracy: 0.7643 - val_loss: 3.4199 - val_accuracy: 0.1467
Epoch 10/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.8869 - accuracy: 0.7743 - val_loss: 3.6645 - val_accuracy: 0.1733
Epoch 11/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.8176 - accuracy: 0.7886 - val_loss: 3.2560 - val_accuracy: 0.2133
Epoch 12/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.7250 - accuracy: 0.8143 - val_loss: 3.3442 - val_accuracy: 0.2467
Epoch 13/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.6523 - accuracy: 0.8300 - val_loss: 3.3131 - val_accuracy: 0.2733
Epoch 14/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.6147 - accuracy: 0.8300 - val_loss: 3.2735 - val_accuracy: 0.2667
Epoch 15/150
640/700 [==========================>...] - ETA: 0s - loss: 0.5316 - accuracy: 0.8719
Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
700/700 [==============================] - 1s 2ms/sample - loss: 0.5564 - accuracy: 0.8629 - val_loss: 3.2213 - val_accuracy: 0.2533
Epoch 16/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.4891 - accuracy: 0.8714 - val_loss: 2.9581 - val_accuracy: 0.3133
Epoch 17/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.3988 - accuracy: 0.9071 - val_loss: 3.0598 - val_accuracy: 0.3333
Epoch 18/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.3535 - accuracy: 0.9214 - val_loss: 3.0337 - val_accuracy: 0.3333
Epoch 19/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.3107 - accuracy: 0.9243 - val_loss: 2.9325 - val_accuracy: 0.3067
Epoch 20/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.3126 - accuracy: 0.9286 - val_loss: 2.9959 - val_accuracy: 0.3000
Epoch 21/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.2947 - accuracy: 0.9200 - val_loss: 3.0396 - val_accuracy: 0.3133
Epoch 22/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.2550 - accuracy: 0.9329 - val_loss: 3.2011 - val_accuracy: 0.3200
Epoch 23/150
672/700 [===========================>..] - ETA: 0s - loss: 0.2298 - accuracy: 0.9420
Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
700/700 [==============================] - 1s 2ms/sample - loss: 0.2272 - accuracy: 0.9429 - val_loss: 3.4700 - val_accuracy: 0.3200
Epoch 24/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.1914 - accuracy: 0.9529 - val_loss: 3.3715 - val_accuracy: 0.3133
Epoch 25/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.1877 - accuracy: 0.9557 - val_loss: 3.1617 - val_accuracy: 0.3200
Epoch 26/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.1458 - accuracy: 0.9871 - val_loss: 3.3660 - val_accuracy: 0.3200
Epoch 27/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.1365 - accuracy: 0.9800 - val_loss: 3.1176 - val_accuracy: 0.3533
Epoch 28/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.1404 - accuracy: 0.9814 - val_loss: 3.3232 - val_accuracy: 0.3400
Epoch 29/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.1226 - accuracy: 0.9743 - val_loss: 3.2392 - val_accuracy: 0.3267
Epoch 30/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.1319 - accuracy: 0.9757 - val_loss: 3.2903 - val_accuracy: 0.3467
Epoch 31/150
672/700 [===========================>..] - ETA: 0s - loss: 0.1001 - accuracy: 0.9821
Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
700/700 [==============================] - 1s 1ms/sample - loss: 0.1016 - accuracy: 0.9814 - val_loss: 3.3053 - val_accuracy: 0.3467
Epoch 32/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.0968 - accuracy: 0.9900 - val_loss: 3.2667 - val_accuracy: 0.3467
Epoch 33/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.0880 - accuracy: 0.9886 - val_loss: 3.2352 - val_accuracy: 0.3667
Epoch 34/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.0766 - accuracy: 0.9900 - val_loss: 3.3934 - val_accuracy: 0.3333
Epoch 35/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.0871 - accuracy: 0.9900 - val_loss: 3.3435 - val_accuracy: 0.3400
Epoch 36/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.0779 - accuracy: 0.9900 - val_loss: 3.3689 - val_accuracy: 0.3533
Epoch 37/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.0815 - accuracy: 0.9900 - val_loss: 3.3746 - val_accuracy: 0.3600
Epoch 38/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.0736 - accuracy: 0.9957 - val_loss: 3.3325 - val_accuracy: 0.3467
Epoch 39/150
672/700 [===========================>..] - ETA: 0s - loss: 0.0640 - accuracy: 0.9955
Epoch 00039: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
700/700 [==============================] - 1s 1ms/sample - loss: 0.0633 - accuracy: 0.9957 - val_loss: 3.3911 - val_accuracy: 0.3467
Epoch 40/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.0636 - accuracy: 0.9971 - val_loss: 3.4314 - val_accuracy: 0.3333
Epoch 41/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.0646 - accuracy: 0.9914 - val_loss: 3.4207 - val_accuracy: 0.3400
Epoch 42/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.0581 - accuracy: 0.9943 - val_loss: 3.4383 - val_accuracy: 0.3133
Epoch 43/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.0532 - accuracy: 1.0000 - val_loss: 3.4532 - val_accuracy: 0.3267
Epoch 44/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.0577 - accuracy: 0.9957 - val_loss: 3.4463 - val_accuracy: 0.3200
Epoch 45/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.0542 - accuracy: 0.9957 - val_loss: 3.4407 - val_accuracy: 0.3333
Epoch 46/150
700/700 [==============================] - 1s 2ms/sample - loss: 0.0496 - accuracy: 0.9986 - val_loss: 3.4102 - val_accuracy: 0.3333
Epoch 47/150
672/700 [===========================>..] - ETA: 0s - loss: 0.0561 - accuracy: 0.9970
Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
700/700 [==============================] - 1s 1ms/sample - loss: 0.0569 - accuracy: 0.9971 - val_loss: 3.4310 - val_accuracy: 0.3400
Epoch 48/150
700/700 [==============================] - 1s 1ms/sample - loss: 0.0575 - accuracy: 0.9943 - val_loss: 3.4415 - val_accuracy: 0.3333
[DEBUG] 模型训练完成

=== 最终性能对比 ===
模型名称                 |    训练时间(s) |   Top1准确率(%) |   Top3准确率(%)
------------------------------------------------------------
deeper_model         |     1854.4 |        22.00 |        46.00
2dcnn                |     1266.3 |        25.33 |        56.67
lstm_model           |       80.0 |        17.33 |        40.00
1dcnn_lstm           |       58.7 |        24.67 |        50.00
1dcnn_pool_lstm      |       55.6 |        27.33 |        49.33

Top 20 Error Pairs:
True: 17 → Pred: 15 | 错误次数:   2
True: 34 → Pred: 36 | 错误次数:   2
True: 42 → Pred: 44 | 错误次数:   2
True:  3 → Pred:  9 | 错误次数:   2
True: 22 → Pred: 26 | 错误次数:   2
True: 40 → Pred: 32 | 错误次数:   2
True: 15 → Pred: 10 | 错误次数:   1
True: 27 → Pred: 22 | 错误次数:   1
True: 15 → Pred: 14 | 错误次数:   1
True: 21 → Pred: 27 | 错误次数:   1
True: 21 → Pred: 24 | 错误次数:   1
True: 10 → Pred:  2 | 错误次数:   1
True: 27 → Pred: 33 | 错误次数:   1
True:  3 → Pred: 16 | 错误次数:   1
True: 21 → Pred: 38 | 错误次数:   1
True: 33 → Pred: 44 | 错误次数:   1
True: 39 → Pred: 40 | 错误次数:   1
True: 39 → Pred: 45 | 错误次数:   1
True: 33 → Pred: 37 | 错误次数:   1
True: 20 → Pred: 46 | 错误次数:   1
Detailed Classification Report:
              precision    recall  f1-score   support

           0     0.5000    0.6667    0.5714         3
           1     0.3333    0.3333    0.3333         3
           2     0.0000    0.0000    0.0000         3
           3     0.0000    0.0000    0.0000         3
           4     0.0000    0.0000    0.0000         3
           5     0.0000    0.0000    0.0000         3
           6     0.0000    0.0000    0.0000         3
           7     0.0000    0.0000    0.0000         3
           8     0.5000    0.3333    0.4000         3
           9     0.2500    0.6667    0.3636         3
          10     0.0000    0.0000    0.0000         3
          11     0.6667    0.6667    0.6667         3
          12     0.5000    0.3333    0.4000         3
          13     0.3333    0.3333    0.3333         3
          14     0.5000    0.6667    0.5714         3
          15     0.0000    0.0000    0.0000         3
          16     0.5000    0.3333    0.4000         3
          17     0.3333    0.3333    0.3333         3
          18     0.6667    0.6667    0.6667         3
          19     1.0000    0.3333    0.5000         3
          20     0.3333    0.3333    0.3333         3
          21     0.0000    0.0000    0.0000         3
          22     0.0000    0.0000    0.0000         3
          23     0.4000    0.6667    0.5000         3
          24     0.0000    0.0000    0.0000         3
          25     0.5000    0.3333    0.4000         3
          26     0.0000    0.0000    0.0000         3
          27     0.0000    0.0000    0.0000         3
          28     0.5000    0.6667    0.5714         3
          29     0.0000    0.0000    0.0000         3
          30     0.0000    0.0000    0.0000         3
          31     0.0000    0.0000    0.0000         3
          32     0.2500    0.6667    0.3636         3
          33     0.0000    0.0000    0.0000         3
          34     0.0000    0.0000    0.0000         3
          35     0.0000    0.0000    0.0000         3
          36     0.2857    0.6667    0.4000         3
          37     0.2500    0.3333    0.2857         3
          38     0.1429    0.3333    0.2000         3
          39     1.0000    0.3333    0.5000         3
          40     0.3333    0.3333    0.3333         3
          41     0.4000    0.6667    0.5000         3
          42     0.0000    0.0000    0.0000         3
          43     1.0000    0.6667    0.8000         3
          44     0.2000    0.3333    0.2500         3
          45     0.3333    0.3333    0.3333         3
          46     0.3750    1.0000    0.5455         3
          47     0.0000    0.0000    0.0000         3
          48     0.0000    0.0000    0.0000         3
          49     0.5000    0.3333    0.4000         3

    accuracy                         0.2733       150
   macro avg     0.2577    0.2733    0.2451       150
weighted avg     0.2577    0.2733    0.2451       150

